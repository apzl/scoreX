{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inpainting.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjjMc_6lk9NR",
        "outputId": "21a6a8a5-6e9f-4a0a-ebee-dee4b85787ab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8E8zml5lKDT"
      },
      "source": [
        "!wget -L https://download.openmmlab.com/mmediting/inpainting/deepfillv2/deepfillv2_256x256_8x2_places_20200619-10d15793.pth -P ./checkpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq9ED653lnlm"
      },
      "source": [
        "import os\n",
        "os.chdir('drive/MyDrive/mmediting')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNy2pVmRlYro"
      },
      "source": [
        "!python3 demo/inpainting_demo.py configs/inpainting/deepfillv2/deepfillv2_256x256_8x2_places.py checkpoint/latest.pth ../../../park4out.jpg ../../../park4mask.jpg ../../../out.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlrHILYp6yRw",
        "outputId": "6d4120eb-dad4-4272-eb5c-91dc09dae06f"
      },
      "source": [
        "!python tools/train.py configs/inpainting/deepfillv2/deepfillv2_256x256_8x2_places.py "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-29 11:28:15,503 - mmedit - INFO - Environment info:\n",
            "------------------------------------------------------------\n",
            "sys.platform: linux\n",
            "Python: 3.7.11 (default, Jul  3 2021, 18:01:19) [GCC 7.5.0]\n",
            "CUDA available: True\n",
            "GPU 0: Tesla K80\n",
            "CUDA_HOME: /usr/local/cuda\n",
            "NVCC: Build cuda_11.0_bu.TC445_37.28845127_0\n",
            "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "PyTorch: 1.9.0+cu102\n",
            "PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 10.2\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\n",
            "  - CuDNN 7.6.5\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
            "\n",
            "TorchVision: 0.10.0+cu102\n",
            "OpenCV: 4.1.2\n",
            "MMCV: 1.3.9\n",
            "MMCV Compiler: GCC 7.5\n",
            "MMCV CUDA Compiler: 11.0\n",
            "MMEditing: 0.9.0+642b759\n",
            "------------------------------------------------------------\n",
            "\n",
            "2021-07-29 11:28:15,504 - mmedit - INFO - Distributed training: False\n",
            "2021-07-29 11:28:15,504 - mmedit - INFO - mmedit Version: 0.9.0\n",
            "2021-07-29 11:28:15,505 - mmedit - INFO - Config:\n",
            "/content/drive/My Drive/mmediting/configs/inpainting/deepfillv2/deepfillv2_256x256_8x2_places.py\n",
            "model = dict(\n",
            "    type='TwoStageInpaintor',\n",
            "    disc_input_with_mask=True,\n",
            "    encdec=dict(\n",
            "        type='DeepFillEncoderDecoder',\n",
            "        stage1=dict(\n",
            "            type='GLEncoderDecoder',\n",
            "            encoder=dict(\n",
            "                type='DeepFillEncoder',\n",
            "                conv_type='gated_conv',\n",
            "                channel_factor=0.75,\n",
            "                padding_mode='reflect'),\n",
            "            decoder=dict(\n",
            "                type='DeepFillDecoder',\n",
            "                conv_type='gated_conv',\n",
            "                in_channels=96,\n",
            "                channel_factor=0.75,\n",
            "                out_act_cfg=dict(type='Tanh'),\n",
            "                padding_mode='reflect'),\n",
            "            dilation_neck=dict(\n",
            "                type='GLDilationNeck',\n",
            "                in_channels=96,\n",
            "                conv_type='gated_conv',\n",
            "                act_cfg=dict(type='ELU'),\n",
            "                padding_mode='reflect')),\n",
            "        stage2=dict(\n",
            "            type='DeepFillRefiner',\n",
            "            encoder_attention=dict(\n",
            "                type='DeepFillEncoder',\n",
            "                encoder_type='stage2_attention',\n",
            "                conv_type='gated_conv',\n",
            "                channel_factor=0.75,\n",
            "                padding_mode='reflect'),\n",
            "            encoder_conv=dict(\n",
            "                type='DeepFillEncoder',\n",
            "                encoder_type='stage2_conv',\n",
            "                conv_type='gated_conv',\n",
            "                channel_factor=0.75,\n",
            "                padding_mode='reflect'),\n",
            "            dilation_neck=dict(\n",
            "                type='GLDilationNeck',\n",
            "                in_channels=96,\n",
            "                conv_type='gated_conv',\n",
            "                act_cfg=dict(type='ELU'),\n",
            "                padding_mode='reflect'),\n",
            "            contextual_attention=dict(\n",
            "                type='ContextualAttentionNeck',\n",
            "                in_channels=96,\n",
            "                conv_type='gated_conv',\n",
            "                padding_mode='reflect'),\n",
            "            decoder=dict(\n",
            "                type='DeepFillDecoder',\n",
            "                in_channels=192,\n",
            "                conv_type='gated_conv',\n",
            "                out_act_cfg=dict(type='Tanh'),\n",
            "                padding_mode='reflect'))),\n",
            "    disc=dict(\n",
            "        type='MultiLayerDiscriminator',\n",
            "        in_channels=4,\n",
            "        max_channels=256,\n",
            "        fc_in_channels=None,\n",
            "        num_convs=6,\n",
            "        norm_cfg=None,\n",
            "        act_cfg=dict(type='LeakyReLU', negative_slope=0.2),\n",
            "        out_act_cfg=dict(type='LeakyReLU', negative_slope=0.2),\n",
            "        with_spectral_norm=True,\n",
            "    ),\n",
            "    stage1_loss_type=('loss_l1_hole', 'loss_l1_valid'),\n",
            "    stage2_loss_type=('loss_l1_hole', 'loss_l1_valid', 'loss_gan'),\n",
            "    loss_gan=dict(\n",
            "        type='GANLoss',\n",
            "        gan_type='hinge',\n",
            "        loss_weight=0.1,\n",
            "    ),\n",
            "    loss_l1_hole=dict(\n",
            "        type='L1Loss',\n",
            "        loss_weight=1.0,\n",
            "    ),\n",
            "    loss_l1_valid=dict(\n",
            "        type='L1Loss',\n",
            "        loss_weight=1.0,\n",
            "    ),\n",
            "    pretrained=None)\n",
            "\n",
            "train_cfg = dict(disc_step=1)\n",
            "test_cfg = dict(metrics=['l1', 'psnr', 'ssim'])\n",
            "\n",
            "dataset_type = 'ImgInpaintingDataset'\n",
            "input_shape = (256, 256)\n",
            "mask_root = 'data/mask'\n",
            "\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile', key='gt_img'),\n",
            "    dict(\n",
            "        type='LoadMask',\n",
            "        mask_mode='set',\n",
            "        mask_config=dict(\n",
            "            mask_list_file=f'{mask_root}/mask_list.txt',\n",
            "            prefix=f'{mask_root}',\n",
            "            io_backend='disk',\n",
            "            flag='unchanged',\n",
            "            file_client_kwargs=dict(),\n",
            "            img_shape=input_shape)),\n",
            "    dict(\n",
            "        type='Crop',\n",
            "        keys=['gt_img'],\n",
            "        crop_size=(384, 384),\n",
            "        random_crop=True,\n",
            "    ),\n",
            "    dict(\n",
            "        type='Resize',\n",
            "        keys=['gt_img'],\n",
            "        scale=input_shape,\n",
            "        keep_ratio=False,\n",
            "    ),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        keys=['gt_img'],\n",
            "        mean=[127.5] * 3,\n",
            "        std=[127.5] * 3,\n",
            "        to_rgb=False),\n",
            "    dict(type='GetMaskedImage'),\n",
            "    dict(\n",
            "        type='Collect',\n",
            "        keys=['gt_img', 'masked_img', 'mask'],\n",
            "        meta_keys=['gt_img_path']),\n",
            "    dict(type='ImageToTensor', keys=['gt_img', 'masked_img', 'mask'])\n",
            "]\n",
            "\n",
            "test_pipeline = train_pipeline\n",
            "\n",
            "data_root = 'data'\n",
            "\n",
            "data = dict(\n",
            "    workers_per_gpu=4,\n",
            "    train_dataloader=dict(samples_per_gpu=2, drop_last=True),\n",
            "    val_dataloader=dict(samples_per_gpu=1),\n",
            "    test_dataloader=dict(samples_per_gpu=1),\n",
            "    train=dict(\n",
            "        type=dataset_type,\n",
            "        ann_file=f'{data_root}/train_list.txt',\n",
            "        data_prefix=data_root,\n",
            "        pipeline=train_pipeline,\n",
            "        test_mode=False),\n",
            "    val=dict(\n",
            "        type=dataset_type,\n",
            "        ann_file=f'{data_root}/val_list.txt',\n",
            "        data_prefix=data_root,\n",
            "        pipeline=test_pipeline,\n",
            "        test_mode=True),\n",
            "    test=dict(\n",
            "        type=dataset_type,\n",
            "        ann_file=(f'{data_root}/val_list.txt'),\n",
            "        data_prefix=data_root,\n",
            "        pipeline=test_pipeline,\n",
            "        test_mode=True))\n",
            "\n",
            "optimizers = dict(\n",
            "    generator=dict(type='Adam', lr=0.0001), disc=dict(type='Adam', lr=0.0001))\n",
            "\n",
            "lr_config = dict(policy='Fixed', by_epoch=False)\n",
            "\n",
            "checkpoint_config = dict(by_epoch=False, interval=50000)\n",
            "log_config = dict(\n",
            "    interval=100,\n",
            "    hooks=[\n",
            "        dict(type='TextLoggerHook', by_epoch=False),\n",
            "        # dict(type='TensorboardLoggerHook'),\n",
            "        #dict(type='PaviLoggerHook', init_kwargs=dict(project='mmedit'))\n",
            "    ])\n",
            "\n",
            "visual_config = dict(\n",
            "    type='VisualizationHook',\n",
            "    output_dir='visual',\n",
            "    interval=1000,\n",
            "    res_name_list=[\n",
            "        'gt_img', 'masked_img', 'stage1_fake_res', 'stage1_fake_img',\n",
            "        'stage2_fake_res', 'stage2_fake_img', 'fake_gt_local'\n",
            "    ],\n",
            ")\n",
            "\n",
            "evaluation = dict(interval=500)\n",
            "\n",
            "total_iters = 10\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "work_dir = 'checkpoint'\n",
            "load_from = None\n",
            "resume_from = None\n",
            "workflow = [('train', 10000)]\n",
            "exp_name = 'deepfillv2.pth'\n",
            "find_unused_parameters = False\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "2021-07-29 11:28:20,025 - mmedit - INFO - Start running, host: root@9752b206c00d, work_dir: /content/drive/My Drive/mmediting/checkpoint\n",
            "2021-07-29 11:28:20,027 - mmedit - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) FixedLrUpdaterHook                 \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) FixedLrUpdaterHook                 \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) FixedLrUpdaterHook                 \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) VisualizationHook                  \n",
            "(NORMAL      ) EvalIterHook                       \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "2021-07-29 11:28:20,027 - mmedit - INFO - workflow: [('train', 10000)], max: 10 iters\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3658: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "2021-07-29 11:28:28,725 - mmedit - INFO - Saving checkpoint at 10 iterations\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0q5iT9Dsd7K"
      },
      "source": [
        "!pip install mmedit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbsO3PKrokl0"
      },
      "source": [
        "import os\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kobH-Xuq6xBi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}